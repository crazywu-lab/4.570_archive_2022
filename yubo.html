<!DOCTYPE html>

<html>
  <head>
    <title>Yubo Zhao</title>
    <meta content="text/html; charset=windows-1252" http-equiv="Content-Type" />
    <meta name="GENERATOR" content="MSHTML 9.00.8112.16484" />
    <style type="text/css">
      .imgs {
        border: thin solid #666;
      }
    </style>
  </head>

  <!-- for black background -->
  <!-- BODY text=#ffffff vLink=#6666ff aLink=#ffffff link=#66ffff bgColor=#000000 -->
  <!-- for white background -->
  <!-- BODY text=#000000 vLink=#666622 aLink=#ff6622 link=#aa6622 bgColor=#ffffff -->

  <body
    text="#000000"
    vlink="#666622"
    alink="#ff6622"
    link="#aa6622"
    bgcolor="#ffffff"
  >
    <!-- level 1: text-align:center is needed to circumbent IE bug and centers inside divs -->
    <div style="text-align: center; top: 0px; left: 0px">
      <!-- level 2: secure a centered fixed-sized area that gets scrolled by browser's scroller -->
      <div
        id="main_area"
        style="
          text-align: left;
          position: relative;
          font-family: 'Times New Roman', Times, serif;
          margin: auto;
          width: 800px;
        "
      >
        <!-- old version... div style="position: absolute; left: 100px; " -->

        <table border="0" cellpadding="10" width="800">
          <tbody>
            <tr>
              <td colspan="2">
                <font size="6">Space-Sentiment Paradigm</font> <br />
                <font size="4">
                  -A Data-driven Framework for Spatial Projection of Emotional Data-</font
                >
                <p>
                  <font size="4"><i>Yubo Zhao</i></font>
                </p>

                <p>
                  Final project for the MIT class
                  <a href="https://cat2.mit.edu/4.570/index.html"
                    >4.550/4.570</a
                  >
                  Computation Design Lab <br />
                  Development: February-May, 2022<br />
                  Instructor: Prof. Takehiko Nagakura, Dr. Daniel Tsai & Prof. Guzden Varinlioglu
                </p>
              </td>
            </tr>
            <tr>
              <td width="500">
                <!-- New html5 video tag + mp4 movie for cross platform.                       -->
                <!-- IE9 (2011 March), Chrome, Safari supported. FF still does not play mp4.   -->
                <!-- If this doc is on scripts.mit.edu, you need chmod 777 on the video files. -->
                <!-- as described in http://scripts.mit.edu/faq/48                             -->

                <img
                  width="400"
                  style="border: 1px solid #999999"
                  height="225"
                  poster="cover.jpg"
                  controls
                  autoplay
                  loop
                  src="./assets/Yubo_Zhao/Highlight_Image.png"
                >
                </img>
              </td>

              <td valign="bottom">
                <p><strong>Emotional Data Projected in Virtual Space</strong></p>
                <p>
                  Illustration by Yubo Zhao
                </p>
              </td>
            </tr>
          </tbody>
        </table>

        <table border="0" cellpadding="10" width="800">
          <tbody>
            <tr>
              <td colspan="3">
                <h2>Project Overview</h2>
                <p>
                  Virtual reality has been used as an efficient tool for iterating and improving spatial design in both real world and its digital twin, yet many measurements of psychological effectiveness in design remain qualitative and irrelevant to specificity of spatial factors. The sentimental feedback of users in a designed space is one of those which lacks direct correlation between emotional and spatial data. For creating more sentimentally impactful and resonating spatial design, a quantitative and space-focused analysis is important to unveil this relationship. Therefore, in this final project, a spatial and sentimental data-driven framework will be introduced to analyze how architectural design factors are spatially tied with emotional state.
                </p>
              </td>
            </tr>
            <tr>
              <td colspan="3"></td>
            </tr>
          </tbody>
        </table>

        <table border="0" cellpadding="10" width="800">
          <tbody>
            <tr>
              <td width="500">
                <img
                  style="border: 1px solid rgb(153, 153, 153)"
                  src="./assets/Yubo_Zhao/Fig 1.png"
                  width="500"
                />
              </td>
              <td valign="bottom">
                <p><strong>Fig 1. Research Motivation and Hypothesis</strong></p>
                <br />
                <p>Psychological reactions and feedbacks in an architectural space are often measured through qualitative and general methods, such as sending questionnaires for feelings about a hallway design, or tracking eye movements on a 2D screen that demonstrates an intersection within a building. This project, in another hand, seeks for a space-relevant, space-specific framework that ties emotional states with spatial factors through an immersive and realistic method of measurement, and subsequently hypothesizes that when proceeding a spatial exploration, certain psychological nuances associated with behavioral and spatial features can be discovered and analyzed.</p>
              </td>
            </tr>
            <tr>
              <td width="500">
                <img
                  style="border: 1px solid rgb(153, 153, 153)"
                  src="./assets/Yubo_Zhao/Fig 2.png"
                  width="500"
                />
              </td>
              <td valign="bottom">
                <p><strong>Fig 2. Method - Design</strong></p>
                <br>
                <p>The experiment provides six different spatial scenarios that vary in scale and proportion, but have same neutralized lighting and material settings in order to isolate the variables of interest. Participant will experience these six ceiling-less white enclosures within a bounded moveable area of 1.5m, located in the center of each space, which also makes the ability of movement unbiased.</p>
              </td>
            </tr>
            <tr>
              <td width="500">
                <img
                  style="border: 1px solid rgb(153, 153, 153)"
                  src="./assets/Yubo_Zhao/Fig 3.png"
                  width="500"
                />
              </td>
              <td valign="bottom">
                <p><strong>Fig 3. Method - Design</strong></p>
                <br>
                <p>The experiment provides six different spatial scenarios that vary in scale and proportion, but have same neutralized lighting and material settings in order to isolate the variables of interest. Participant will experience these six ceiling-less white enclosures within a bounded moveable area of 1.5m, located in the center of each space, which also makes the ability of movement unbiased.</p>
              </td>
            </tr>
            <tr>
              <td width="500">
                <img
                  style="border: 1px solid rgb(153, 153, 153)"
                  src="./assets/Yubo_Zhao/Fig 4.png"
                  width="500"
                />
              </td>
              <td valign="bottom">
                <p><strong>Fig 4. Method – Participants and Apparatus</strong></p>
                <br>
                <p>The experiment is aim to have participants with varying gender, age, and design backgrounds, but only four participants are recruited for this project due to a constrained timeframe. Oculus Quest 2 VR headset is used for the virtual experience, and MUSE 2 headband is used for EEG data collection. </p>
              </td>
            </tr>
            <tr>
              <td width="500">
                <img
                  style="border: 1px solid rgb(153, 153, 153)"
                  src="./assets/Yubo_Zhao/Fig 5.png"
                  width="500"
                />
              </td>
              <td valign="bottom">
                <p><strong>Fig 5. Method - Procedure</strong></p>
                <br>
                <p>Participants will involve in the experiment in two ways: a self-reporting questionnaire that qualitatively measures their emotional state before and after the spatial experience and enables them to pick a personally preferred option, and a virtual journey that sequentially leads them through six enclosures with a transitional scene in between two spaces in order to counter-balancing the psychological impact of spatial shift. </p>
              </td>
            </tr>
            <tr>
              <td width="500">
                <img
                  style="border: 1px solid rgb(153, 153, 153)"
                  src="./assets/Yubo_Zhao/Fig 6.png"
                  width="500"
                />
              </td>
              <td valign="bottom">
                <p><strong>Fig 6. Method – Questionnaire</strong></p>
                <br>
                <p>Questionnaire asks standard self-reporting questions such as current and post-VR feelings, with the additional selection of participants’ favorite space.</p>
              </td>
            </tr>
            <tr>
              <td width="500">
                <img
                  style="border: 1px solid rgb(153, 153, 153)"
                  src="./assets/Yubo_Zhao/Fig 7.png"
                  width="500"
                />
              </td>
              <td valign="bottom">
                <p><strong>Fig 7. Method - Tech Architecture</strong></p>
                <br>
                <p>The EEG data is synced with the head position of participants via a customized script and records every second. The output CSV file is sent to Grasshopper to be parsed with a customized code and visualized and rendered in Rhino 7.</p>
              </td>
            </tr>
            <tr>
              <td width="500">
                <img
                  style="border: 1px solid rgb(153, 153, 153)"
                  src="./assets/Yubo_Zhao/Fig 8.png"
                  width="500"
                />
              </td>
              <td valign="bottom">
                <p><strong>Fig 8. Method – Brainwave Selection</strong></p>
                <br>
                <p>While brainwaves with five different frequencies are commonly used for decoding emotional states, two of them (Beta and Theta) are selected with a focus on the concentration level and arousal level.</p>
              </td>
            </tr>
            <tr>
              <td width="500">
                <img
                  style="border: 1px solid rgb(153, 153, 153)"
                  src="./assets/Yubo_Zhao/Fig 9_GIF.gif"
                  width="500"
                />
              </td>
              <td valign="bottom">
                <p><strong>Fig 9. Method – EEG&VR Integration</strong></p>
                <br>
                <p>EEG data is synced with the head position and view direction of participants through a customized script, which can be seen in this demo.</p>
              </td>
            </tr>
            <tr>
              <td width="500">
                <img
                  style="border: 1px solid rgb(153, 153, 153)"
                  src="./assets/Yubo_Zhao/Fig 10.png"
                  width="500"
                />
              </td>
              <td valign="bottom">
                <p><strong>Fig 10. Results - Emotional Data of Four Participants Projected in Space</strong></p>
              </td>
            </tr>
            <tr>
              <td width="500">
                <img
                  style="border: 1px solid rgb(153, 153, 153)"
                  src="./assets/Yubo_Zhao/Fig 11.png"
                  width="500"
                />
              </td>
              <td valign="bottom">
                <p><strong>Fig 11. Results - Emotional Data of Four Participants Projected in Space</strong></p>
              </td>
            </tr>
            <tr>
              <td width="500">
                <img
                  style="border: 1px solid rgb(153, 153, 153)"
                  src="./assets/Yubo_Zhao/Fig 12.png"
                  width="500"
                />
              </td>
              <td valign="bottom">
                <p><strong>Fig 12. Results - Emotional Data of Four Participants Projected in Space</strong></p>
              </td>
            </tr>
            <tr>
              <td width="500">
                <img
                  style="border: 1px solid rgb(153, 153, 153)"
                  src="./assets/Yubo_Zhao/Fig 13.png"
                  width="500"
                />
              </td>
              <td valign="bottom">
                <p><strong>Fig 13. Results - Emotional Data of Four Participants Projected in Space</strong></p>
              </td>
            </tr>
            <tr>
              <td width="500">
                <img
                  style="border: 1px solid rgb(153, 153, 153)"
                  src="./assets/Yubo_Zhao/Fig 14.png"
                  width="500"
                />
              </td>
              <td valign="bottom">
                <p><strong>Fig 14. Results – Beta Brainwave in 6 Scenarios </strong></p>
                <br>
                <p>This graph demonstrates varying intensities of beta brainwaves that roughly shows the small square room causes the highest level of stress.</p>
              </td>
            </tr>
            <tr>
              <td width="500">
                <img
                  style="border: 1px solid rgb(153, 153, 153)"
                  src="./assets/Yubo_Zhao/Fig 15.png"
                  width="500"
                />
              </td>
              <td valign="bottom">
                <p><strong>Fig 15. Conclusion 1 – Emotional Perspective</strong></p>
                <br>
                <p>Proportion matters. Elongated layout tends to calm people more effectively.</p>
              </td>
            </tr>
            <tr>
              <td width="500">
                <img
                  style="border: 1px solid rgb(153, 153, 153)"
                  src="./assets/Yubo_Zhao/Fig 16.png"
                  width="500"
                />
              </td>
              <td valign="bottom">
                <p><strong>Fig 16. Conclusion 1 – Emotional Perspective</strong></p>
                <br>
                <p>The importance of scale is a bit vague, yet generally speaking, participants in large rooms slightly lose (active) concentration.</p>
              </td>
            </tr>
            <tr>
              <td width="500">
                <img
                  style="border: 1px solid rgb(153, 153, 153)"
                  src="./assets/Yubo_Zhao/Fig 17.png"
                  width="500"
                />
              </td>
              <td valign="bottom">
                <p><strong>Fig 17. Conclusion 3 – Emotional Perspective</strong></p>
              </td>
            </tr>
            <tr>
              <td width="500">
                <img
                  style="border: 1px solid rgb(153, 153, 153)"
                  src="./assets/Yubo_Zhao/Fig 18.png"
                  width="500"
                />
              </td>
              <td valign="bottom">
                <p><strong>Fig 18. Conclusion 4 – Behavioral Perspective</strong></p>
              </td>
            </tr>
            <tr>
              <td width="500">
                <img
                  style="border: 1px solid rgb(153, 153, 153)"
                  src="./assets/Yubo_Zhao/Fig 19.png"
                  width="500"
                />
              </td>
              <td valign="bottom">
                <p><strong>Fig 19. Conclusion 5 – Subjective Perspective</strong></p>
              </td>
            </tr>
          </tbody>
        </table>

        <table border="0" cellpadding="10" width="800">
          <tbody>
            <tr>
              <td height="100">
                <p><strong>Future Steps</strong></p>
                <p>
                  1. Improve the statistical validity and collect more data from a larger pool of participants.
                  <br><br>
                  2.Redesign the self-report survey as the current questionnaire lacks the level of detail and specificity that associates with spatial features.
                  <br><br>
                  3.Deepen the analytical part of the research and explore more concise and insightful method of spatial data visualization
                  <br><br>
                  4.Develop a platform tool that can provide access to other spatial designers in a professional production workflow.
                </p>
                <!-- <p>&nbsp;</p> -->
              </td>
              
            </tr>
          </tbody>
        </table>

        <table border="0" cellpadding="10" width="800">
          <tbody>
            <tr>
              <td height="100">
                <p><strong>References</strong></p>
                <p>
                  Evans, Gary W. “Environmental Cognition.” Psychological Bulletin 88, no. 2 (19800101): 259. https://doi.org/10.1037/0033-2909.88.2.259.
                  <br><br>
                  Grassini, Simone, and Karin Laumann. “Questionnaire Measures and Physiological Correlates of Presence: A Systematic Review.” Frontiers in Psychology 11 (2020).
                  <br><br>
                  Jodelet, Denise. “Jodelet, D. &amp; Milgram, S. (1976). Psychological Maps of Paris.” In H. Proshansky, W.H. Ittelson, L.G. Rivlin (Eds.), Environmental Psychology: People and Their Physical Settings (Pp. 104-124). New York, Holt, Rinehart &amp; Winston., January 1, 1976. https://www.academia.edu/12102290/Jodelet_D_and_Milgram_S_1976_Psychological_maps_of_Paris.
                  <br><br>
                  Negami, Hanna R., and Colin G. Ellard. “How Architecture Evokes Awe: Predicting Awe through Architectural Features of Building Interiors.” Psychology of Aesthetics, Creativity, and the Arts, May 2021. https://doi.org/10.1037/aca0000394.
                  <br><br>
                  Shemesh, Avishag, Gerry Leisman, Moshe Bar, and Yasha Jacob Grobman. “A Neurocognitive Study of the Emotional Impact of Geometrical Criteria of Architectural Space.” Architectural Science Review 64, no. 4 (July 4, 2021): 394–407. https://doi.org/10.1080/00038628.2021.1940827.
                <br><br>
                Yoshimura, Yuji, Shan He, Gary Hack, Takehiko Nagakura, and Carlo Ratti. “Quantifying Memories: Mapping Urban Perception.” Mobile Networks and Applications 25, no. 4 (August 1, 2020): 1275–86. https://doi.org/10.1007/s11036-020-01536-0.
                </p>
                <p>&nbsp;</p>
              </td>
              
            </tr>
          </tbody>
        </table>

        <hr />
        <div
          id="tail"
          style="
            text-align: center;
            margin: auto;
            width: 800px;
            font-size: 0.8em;
            color: #dddddd;
            background-color: #000000;
          "
        >
          <!-- click the counter on the page to see the instruction by SIPB -->
          <a href="http://stuff.mit.edu/doc/counter-howto.html">
            <!-- the identifier needs to be unique to this page -->
            <img
              src="http://stuff.mit.edu/cgi/counter/takehiko_counter_katya_201306"
              alt="several"
              border="0"
          /></a>
          <br />2013 All rights reserved. &nbsp;&nbsp; Last modified: Jan. 30,
          2014 by TN
        </div>
      </div>
      <!-- level 1 ends -->
    </div>
    <!-- level 2 ends -->
  </body>
</html>
